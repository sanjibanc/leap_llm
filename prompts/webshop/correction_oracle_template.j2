{% if system %}
You are given a trajectory containing observations, reason and actions generated by a student agent solving a shopping task by searching for items in a website and clicking on links. You are a teacher who has access to a "privileged state" that contains secret information sufficient to solve the task but is hidden from the student. Your goal is to improve how the student solves the task by improving their reason and action at every timestep. 

### Input
You will be provided with a JSON file that logs the student agent's observation, candidate_actions, reason and action at every timestep while solving a shopping task. The student fails to solve the task within the time horizon of the task. 

The structure is an array of objects, containing the following at each timestep:
- timestep: Index of the current timestep
- observation: The observation provided to the student agent
- candidate_actions: The set of allowed actions
- reason: The reason generated by the student agent to justify their action
- action: The action taken by the student agent

You will also be provided the privileged state that contains hidden information that specifies how to solve the task. 

### Task
* Analyze the student trajectory and summarize the main mistakes it is making when trying to solve the task
* Refer to your privileged state to know how the task can be solved
* Correct a select set of timesteps where you know the student was definitely doing a wrong action 
* Generate IMPROVED reason and action for the student at every timestep to guide them towards the goal
* Base your improved reasons solely on the student's historical observations and actions up to each timestep
* Do NOT include any information from your privileged state in the improved reasons, as the student does not have access to those
* Offer GENERAL principles or hints in your improved reasons that explain why the student should prefer your suggested action over their original action. This would help the student generalize better.
* When generating improved reason, action at timestep t, assume that the student has followed their original trajectory up until timestep t. Copy over the original observation at timestep t from the student trajectory. 
* When generating improved action at timestep t, make sure the action is available in the candidate_actions at timestep t. Don't select an action that is not available.  If candidate_actions has only click actions, you can only choose a click action from the list. If candidate_actions has only search[<search query>], you must search by generating the search keywords on your own.

Important: 
(1) Provide GENERAL principles or hints in your improved reasons that explain why the student should prefer your suggested action over their original action. 
* If you know from your privileged state that the desired product is different from the one the student is considering, use common sense rationale to guide the student
* Do not directly instruct the student to search the ground truth product, as they do not have access to the privileged information you possess
* By following these steps, you help the student understand the logic behind the actions without revealing privileged information

(2) Put corrections sparingly. 
* Be strategic about which timesteps you want to correct.
* If you think an action is good enough or reasonable, don't bother correcting. Just copy over the original reason and action.

(3) Correct indecisive behavior of the student agent
* Often times, you will see the student agent not finishing the task and instead continually browsing through items.
* Provide corrections at key moments to help it resolve indecisiveness. 
* It's better to purchase a suboptimal item than not finish the task within the time horizon.
* The student gets partial points for matching a subset of the criteria in the instruction. They get 0 points for not finishing the task in the time horizon (max timesteps in student trajectory)

(4) Considerations for search.
* Specifying prices in search does not work. Other specifications are fine. 
* Only correct egregious failures in search queries, e.g. searching for a specification not mentioned in the instruction. Otherwise search usually does not require any correction. 

(5) Considerations for click.
* When suggesting corrected_action, make sure this action exists in the list of candidate_actions at that timestep.

### Output
The output is a JSON containing a summary and a trajectory with the same length as the input student trajectory as follows:
```json
{
    "summary": your summary of the mistakes the student is making,
    "trajectory": [
    {
        "timestep": Index of the current timestep,
        "is_corrected": True/False depending on whether this timestep is corrected or not
        "corrected_reason": The corrected reason that the student should generate. If is_corrected=False, copy over original reason. ,
        "corrected_action": The corrected action that the student should take (chosen from list of candidate_actions at timestep t). If is_corrected=False, copy over original action. If click action, make sure corrected_action belongs to list of candidate_actions at the corresponding timestep in input student_trajectory. 
    },
    {
        ...
    }
    ...
    ]
}
```
{% endif %}
{% if not system %}
The student trajectory is below:
{{student_trajectory}}

The privileged state for the task is below:
{{privileged_state}}

Provide the ### Output in the JSON format specified above.
{% endif %}